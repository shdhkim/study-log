# 머신러닝 데이터셋 분할 및 하이퍼파라미터 탐색 기법 정리

## 훈련셋 (Training set)
- 모델이 실제로 학습하는 데이터.
- 가중치(weight) 및 파라미터(parameter)를 업데이트할 때 사용됨.
- 모델이 패턴을 익히도록 도움.

### 예시: 기출문제집
- 문제 유형을 익히고 풀이 방법을 반복 학습함.

---

## 유효셋 (Validation set)
- 하이퍼파라미터 튜닝(학습률, 레이어 수, 규제 강도 등)에 사용됨.
- 조기 종료(early stopping) 기준 설정에도 활용.
- 모델의 일반화 성능을 간접 평가.
- 훈련 과정에서 가중치 업데이트에는 사용되지 않음.

### 예시: 모의고사
- 시간 배분, 전략 조정에 활용.
- 성적을 보고 학습 전략 수정 가능.
- 정답을 외워선 안 됨 (학습에는 직접 사용되지 않음).

---

## 테스트셋 (Test set)
- 학습 및 튜닝에 전혀 사용되지 않은 새로운 데이터.
- 모델 개발 완료 후, 최종 성능을 한 번만 평가.
- 현업에서 기대할 수 있는 실질적인 성능 판단용.

### 예시: 본시험
- 절대 미리 볼 수 없음.
- 최종 성적을 통해 실력 객관적 평가.

---

## 실제 모의고사 vs 머신러닝 유효셋
- **사람:** 정답 자체도 기억하게 되어 다음 시험에 유리.
- **ML 모델:** 유효셋의 정답은 가중치 업데이트에 사용되지 않음 → 기억 불가능, 오직 간접적인 튜닝용.

---

## K-Fold 교차 검증 (Cross Validation)
- 데이터를 k개의 동일한 부분(fold)로 나눔.
- 매 반복에서 하나의 fold는 검증용, 나머지 k-1개는 훈련용으로 사용.
- 이 과정을 k번 반복하여 모든 fold가 검증에 한 번씩 사용됨.
- 최종 성능은 k개의 검증 성능 평균으로 평가.

### 수행 과정
1. 전체 데이터를 k개로 나눔
2. k번 반복:
   - i번째 반복에서는 i번째 fold를 검증용으로 사용
   - 나머지 fold들을 훈련용으로 사용
3. 각 반복마다 모델 학습 및 검증 성능 기록
4. 성능 평균 계산

---

## 불편추정량 (Unbiased Estimator)
- 어떤 모수(parameter)를 추정할 때,
- 해당 추정량의 기댓값이 실제 모수와 같으면 불편추정량이라 함.

---

## 미니 모델링 (Mini Modeling)
- 데이터 분석, 머신러닝, 시스템 설계 초기에 작은 규모로 모델을 만들어 실험.
- 아이디어 검증 및 구조 검토에 유리함.

---

## 하이퍼파라미터 탐색 기법

### 그리드 서치 (Grid Search)
- **개념:** 지정한 모든 하이퍼파라미터 조합 실험.
- **탐색 방식:** 전체 탐색 (Exhaustive Search).
- **계산 비용:** 큼 (조합 수가 많을수록 기하급수적으로 증가).
- **효율성:** 고정된 그리드 내에서만 탐색 → 최적값을 놓칠 수 있음.

### 랜덤 서치 (Random Search)
- **개념:** 지정된 범위 내에서 일부 조합만 무작위로 실험.
- **탐색 방식:** 확률적 탐색 (Random Sampling).
- **계산 비용:** 낮음 (샘플 수만 지정하면 됨).
- **효율성:** 더 넓고 유연한 탐색 가능.

### 베이지안 서치 (Bayesian Search)
- **개념:** 이전 탐색 결과를 바탕으로 다음 하이퍼파라미터 조합을 확률적으로 선택.
- **특징:** 성능이 좋아질 가능성이 높은 방향으로 탐색을 유도.
- **장점:** 탐색 효율성과 정확성 모두 높음.