
## **표준 정규분포를 사용하는 이유**
- 서로 다른 정규분포(예: 사람의 키, 시험 점수 등)를 동일한 기준으로 비교할 수 있도록 함.
- 예를 들어, 평균 170cm, 표준편차 6cm인 키의 정규분포에서 키가 180cm 이상일 확률을 구하는 방법:
  - Z-점수 변환: (180-170)/6 = 10/6

## **Min-Max Scaler의 특징**
- 모든 데이터가 동일한 범위(0~1 또는 다른 범위)로 변환됨.
- 데이터 분포의 형태를 유지 → 기존의 데이터 구조를 보존.
- 이상치(Outliers)에 민감함 → 최대값, 최소값이 이상치라면 스케일링된 값이 왜곡될 수 있음.
- 딥러닝 및 이미지 처리에서 자주 사용되며, 특히 신경망의 입력 데이터를 정규화할 때 유용.
- 데이터가 특정 구간에 몰려 있지 않고, 전반적으로 균일하게 퍼져 있는 경우 쓰는 게 좋음.

## **상관관계(Correlation)와 인과관계(Causation)**
- 상관관계: 두 변수(X, Y)가 함께 변하는 경향이 있다는 것을 의미.
- 인과관계와 다름: X가 Y의 원인이 된다는 것을 의미하지 않음.
- 예시:
  - 상관관계: 집에서 공부 시간이 많을수록 성적이 높음.
  - 잘못된 인과 해석: 집에서 공부를 많이 하면 무조건 성적이 높아진다.
  - 실제 원인: 공부하는 태도, 학원, 학교 수업 참여도 등 여러 요인이 함께 영향을 줄 수 있음.

## **선형과 비선형**
- 선형: 단순하지만 이해하기 쉽고 해석이 용이함.
- 비선형: 복잡하지만 현실 세계에서 더 많이 나타나는 패턴.
- 피어슨 상관계수는 선형 관계만 측정 가능 → 비선형 관계를 정확히 반영하지 못함.
- 비선형 관계를 분석하려면 스피어만 상관계수(Spearman Correlation)나 비선형 회귀 분석 사용 필요.

## **편상관계수(Partial Correlation Coefficient)**
- 일반적인 상관계수는 두 변수 간의 관계만 측정.
- 편상관계수는 다른 변수의 영향을 제거하고 두 변수 간의 순수한 관계를 측정.
- 예시:
  - 공부 시간(X)과 성적(Y)의 상관관계를 구할 때,
  - 학원 수업 시간(Z)도 성적에 영향을 미칠 수 있음.
  - 학원 수업 시간(Z)의 영향을 제거하고, 공부 시간(X)과 성적(Y) 간의 순수한 관계만 분석하는 것이 편상관계수.

## **유의 수준(Significance Level)과 가설 검정**
- 유의 수준(α) = 0.05: "잘못된 결론(오류)을 내릴 확률이 5%".
- P-value 해석:
  - P < 0.05 → 귀무가설 기각 (차이 있음).
  - P ≥ 0.05 → 귀무가설 채택 (차이 없음).
- 1종 오류(Type I Error): 귀무가설이 참인데 이를 잘못 기각하는 오류.
- 2종 오류(Type II Error): 대립가설이 참인데 이를 잘못 채택하는 오류.

## **카이제곱 분포(Chi-Square Distribution)와 자유도(Degrees of Freedom, df)**
- 모집단의 분산을 추정하거나 범주형 데이터의 독립성을 검정할 때 사용됨.
- 자유도(df): 독립적으로 변할 수 있는 데이터 개수.
  - 예: 평균이 10이라는 조건에서 5개의 데이터가 있다면 자유도(df) = 5 - 1 = 4.

## **회귀(Regression)와 분류(Classification)**
- 회귀 모델: 출력값이 연속형(Continuous) 데이터.
- 분류 모델: 출력값이 범주형(Categorical) 데이터.

## **다중공선성(Multicollinearity)**
- 독립 변수들 간의 상관관계가 높은 경우 회귀 모델 성능 저하 가능.

## **잔차(Residuals)와 등분산성(Homoscedasticity)**
- 잔차(Residuals) = 실제 값 - 예측 값.
- 잔차가 정규 분포를 따르고 패턴 없이 랜덤해야 모델이 적절함.
- 등분산성: 잔차의 분산이 일정한 특성.

## **결정계수(R²)와 수정된 결정계수**
- 결정계수(R²): 독립 변수가 종속 변수의 변동을 얼마나 설명하는지를 나타내는 수치.
- 수정된 결정계수:
  - 불필요한 변수 추가 시 패널티 적용.
  - 모델 성능 향상 여부 평가.
  - 과적합 방지 역할.
  - 변수 선택(Feature Selection)에 활용.

## **로지스틱 회귀(Logistic Regression)**
- 선형 회귀를 기반으로 하지만 실제로는 분류 모델.
- 선형 회귀는 확률값이 0~1 범위를 벗어날 수 있어 문제가 발생.
- 해결책: 로지스틱 회귀의 시그모이드 함수 적용.

## **공분산(Covariance)**
- 두 확률 변수 간의 관계를 나타내는 값.
- 두 변수가 함께 변하는 정도를 측정하는 통계적 개념.